import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.assigners.SlidingProcessingTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;

import java.util.Properties;

public class JsonEventAggregationExample {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // Set up Kafka consumer with a JSON deserializer
        Properties properties = new Properties();
        properties.setProperty("bootstrap.servers", "localhost:9092");
        properties.setProperty("group.id", "my-consumer-group");

        FlinkKafkaConsumer<String> kafkaConsumer = new FlinkKafkaConsumer<>(
                "your-kafka-topic",
                new SimpleStringSchema(),
                properties
        );

        // Create a data stream from Kafka
        DataStream<String> stream = env.addSource(kafkaConsumer);

        // Parse JSON events into a custom event class
        DataStream<Event> eventStream = stream.map(jsonString -> {
            ObjectMapper objectMapper = new ObjectMapper();
            JsonNode jsonNode = objectMapper.readTree(jsonString);
            String key = jsonNode.get("key").asText();
            int value = jsonNode.get("value").asInt();
            return new Event(key, value);
        });

        // Apply windowing and aggregation
        DataStream<AggregateResult> aggregatedStream = eventStream
                .keyBy(Event::getKey)
                .window(SlidingProcessingTimeWindows.of(Time.seconds(10), Time.seconds(5)))
                .aggregate(new EventAggregateFunction());

        // Print the aggregated results to stdout
        aggregatedStream.print();

        // Execute the Flink job
        env.execute("Event Aggregation Example");
    }

    public static class Event {
        private String key;
        private int value;

        public Event(String key, int value) {
            this.key = key;
            this.value = value;
        }

        // getters, setters, and constructors

        // ...
    }

    public static class AggregateResult {
        private String key;
        private int sum;
        private int count;

        // getters, setters, and constructors

        // ...
    }

    public static class EventAggregateFunction implements AggregateFunction<Event, AggregateResult, AggregateResult> {
        @Override
        public AggregateResult createAccumulator() {
            return new AggregateResult("", 0, 0);
        }

        @Override
        public AggregateResult add(Event event, AggregateResult accumulator) {
            accumulator.setKey(event.getKey());
            accumulator.setSum(accumulator.getSum() + event.getValue());
            accumulator.setCount(accumulator.getCount() + 1);
            return accumulator;
        }

        @Override
        public AggregateResult getResult(AggregateResult accumulator) {
            return accumulator;
        }

        @Override
        public AggregateResult merge(AggregateResult a, AggregateResult b) {
            a.setSum(a.getSum() + b.getSum());
            a.setCount(a.getCount() + b.getCount());
            return a;
        }
    }
}

<dependencies>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-core</artifactId>
        <version>1.17.0</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-java</artifactId>
        <version>1.17.0</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-streaming-java_2.12</artifactId>
        <version>1.17.0</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-clients_2.12</artifactId>
        <version>1.17.0</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-json</artifactId>
        <version>1.17.0</version>
    </dependency>
</dependencies>






import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.time.Time;

public class DataAggregationExample {

    public static void main(String[] args) throws Exception {
        // Set up the execution environment
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // Create a stream of data
        DataStream<Tuple2<String, Integer>> dataStream = env.fromElements(
                new Tuple2<>("Key1", 1),
                new Tuple2<>("Key2", 2),
                new Tuple2<>("Key1", 3),
                new Tuple2<>("Key2", 4),
                new Tuple2<>("Key1", 5),
                new Tuple2<>("Key2", 6)
        );

        // Apply sliding window and keyBy
        DataStream<Tuple2<String, Integer>> resultStream = dataStream
                .keyBy(0) // Key by the first field of the tuple (the key)
                .timeWindow(Time.seconds(5)) // Define a sliding window of 5 seconds
                .aggregate(new CountAggregator()); // Apply the CountAggregator to count the elements

        // Print the result to the console
        resultStream.print();

        // Execute the job
        env.execute("Data Aggregation Example");
    }

    // Custom AggregateFunction to count the elements in the window
    public static class CountAggregator implements AggregateFunction<Tuple2<String, Integer>, Integer, Tuple2<String, Integer>> {

        @Override
        public Integer createAccumulator() {
            return 0;
        }

        @Override
        public Integer add(Tuple2<String, Integer> value, Integer accumulator) {
            return accumulator + 1;
        }

        @Override
        public Tuple2<String, Integer> getResult(Integer accumulator) {
            return new Tuple2<>("Window", accumulator);
        }

        @Override
        public Integer merge(Integer a, Integer b) {
            return a + b;
        }
    }
}

